# InfiR2

<p align="center">
  <b>InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models</b>
</p>

<p align="center">
  <a href="https://scholar.google.com/citations?hl=zh-CN&user=1LA3TSAAAAAJ">Wenjun Wang*</a>,
  <a href="https://scholar.google.com/citations?user=VRlUiqQAAAAJ">Shuo Cai*</a>,
  <a href="https://scholar.google.com/citations?user=I6SAtGMAAAAJ&hl=en">Congkai Xie</a>, Mingfa Feng, Yiming Zhang, Zhen Li, Kejing Yang, Ming Li, Jiannong Cao, Hongxia Yang <br>

</p>


<p align="center">
Â  <a href="https://arxiv.org/abs/2509.22536">ğŸ“„ Paper</a> &nbsp; | &nbsp;
Â  <a href="https://huggingface.co/datasets/ZaynZhu/Paper2Video">ğŸ¤— Huggingface </a> &nbsp; | &nbsp;
Â  <a href="https://infix-ai.com/research/infir2/">ğŸŒ Project Website</a> &nbsp; | &nbsp;
</p>


## ğŸ”¥ æ›´æ–°
- [x] [2025.10.8] æˆ‘ä»¬å‘å¸ƒäº†[ä»£ç ](https://github.com/InfiXAI/InfiR2)å’Œ[æ¨¡å‹](https://huggingface.co/datasets/ZaynZhu/Paper2Video)ã€‚
- [x] [2025.9.26] æˆ‘ä»¬å‘å¸ƒäº† [arXiv è®ºæ–‡](https://arxiv.org/abs/2509.22536)ã€‚


### å†…å®¹
- [ğŸŒŸ æ¦‚è§ˆ](#-æ¦‚è§ˆ)
- [ğŸš€ ç¯å¢ƒå‡†å¤‡](#-ç¯å¢ƒå‡†å¤‡)
- [ğŸ¤– FP8 é¢„è®­ç»ƒ](#-fp8-é¢„è®­ç»ƒ)
- [ğŸŒˆ FP8 ç›‘ç£å¾®è°ƒ](#-fp8-ç›‘ç£å¾®è°ƒ)
- [ğŸ¯ FP8 å¼ºåŒ–å­¦ä¹ ](#-fp8-å¼ºåŒ–å­¦ä¹ )
- [ğŸ“Š è¯„ä¼°](#-è¯„ä¼°)
- [ğŸ™ è‡´è°¢](#-è‡´è°¢)
- [ğŸ“Œ å¼•ç”¨](#-å¼•ç”¨)

---

## ğŸŒŸ æ¦‚è§ˆ

æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„ **FP8 è®­ç»ƒæ–¹æ¡ˆ**ï¼Œæ— ç¼é›†æˆäº†æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨äº†**ç»†ç²’åº¦çš„ã€æ··åˆç²’åº¦çš„é‡åŒ–ç­–ç•¥**ï¼Œåœ¨ä¿æŒæ•°å€¼ä¿çœŸåº¦çš„åŒæ—¶æœ€å¤§åŒ–è®¡ç®—æ•ˆç‡ã€‚é€šè¿‡åœ¨ 160B Token è¯­æ–™åº“ä¸Šè¿›è¡Œæ¨¡å‹çš„æŒç»­é¢„è®­ç»ƒç­‰å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ¡ˆä¸ä»…**éå¸¸ç¨³å®šä¸”åŸºæœ¬æ— æŸ**ï¼Œåœ¨æ‰€æœ‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å‡å®ç°äº†ä¸ BF16 åŸºçº¿ç›¸å½“çš„æ€§èƒ½ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¿™å¸¦æ¥äº†æ˜¾è‘—çš„æ•ˆç‡æå‡ï¼ŒåŒ…æ‹¬**è®­ç»ƒæ—¶é—´å‡å°‘ 22%**ï¼Œ**å³°å€¼å†…å­˜ä½¿ç”¨é™ä½ 14%**ï¼Œä»¥åŠ**ååé‡å¢åŠ  19%**ã€‚æˆ‘ä»¬çš„ç»“æœç¡®ç«‹äº† FP8 ä½œä¸º BF16 çš„ä¸€ä¸ªå®ç”¨ä¸”å¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæˆ‘ä»¬å°†å‘å¸ƒé…å¥—ä»£ç ä»¥è¿›ä¸€æ­¥æ¨åŠ¨å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„æ™®åŠåŒ–ã€‚

<div align="center">
  <img src="assets/fp8_recipe.png" alt="æˆ‘ä»¬çš„æ–¹æ¡ˆ" width="100%">
</div>

## ğŸš€ ç¯å¢ƒå‡†å¤‡

### ç¯å¢ƒé…ç½®

æˆ‘ä»¬æ”¯æŒé€šè¿‡ **Conda** å’Œ **Docker** è¿›è¡Œç¯å¢ƒé…ç½®ã€‚è¿™ä¸¤ç§æ–¹æ³•å‡åŸºäº [THUDM/slime](https://github.com/THUDM/slime) ä»“åº“çš„å®˜æ–¹è®¾ç½®æŒ‡å—ã€‚è¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ä¸­çš„è¯´æ˜ã€‚

---

### æ–¹æ¡ˆ 1: Conda é…ç½®

* **è¯´æ˜**: è¯·éµå¾ª [**THUDM/slime Conda æ„å»ºæ–‡æ¡£**](https://github.com/THUDM/slime/blob/main/docs/README.md) ä¸­çš„è¯¦ç»†æŒ‡å—ã€‚

---

### æ–¹æ¡ˆ 2: Docker é…ç½®

* **è¯´æ˜**: è¯·å‚è€ƒ [**THUDM/slime Docker ç›®å½•**](https://github.com/THUDM/slime/tree/main/docker) ä¸­çš„å®˜æ–¹ Docker é…ç½®æ–‡ä»¶å’ŒæŒ‡å—ã€‚

ä¸ºäº†æ‹‰å–æ­¤ä»“åº“ï¼Œè¯·ä½¿ç”¨
```bash
git clone --recursive https://github.com/InfiXAI/InfiR2
```

## ğŸ¤– FP8 é¢„è®­ç»ƒ

æˆ‘ä»¬æä¾›äº†ä½¿ç”¨ FP8 é‡åŒ–è¿›è¡ŒæŒç»­é¢„è®­ç»ƒçš„è„šæœ¬ã€‚

- 7B CPT
  - warmup å’Œ stable: [`InfiR2_CPT_FP8_7B.sh`](scripts/CPT/InfiR2_CPT_FP8_7B.sh)ã€‚
  - decay: [`InfiR2_CPT_FP8_7B_decay.sh`](scripts/CPT/InfiR2_CPT_FP8_7B_decay.sh)ã€‚
- 1.5B CPT
  - warmup å’Œ stable: [`InfiR2_CPT_FP8_1.5B.sh`](scripts/CPT/InfiR2_CPT_FP8_1.5B.sh)ã€‚
  - decay: [`InfiR2_CPT_FP8_1.5B_decay.sh`](scripts/CPT/InfiR2_CPT_FP8_1.5B_decay.sh)ã€‚

#### Configuration

**è¯·ç›´æ¥åœ¨è„šæœ¬å†…éƒ¨ä¿®æ”¹æ‰€éœ€çš„å‚æ•°ï¼›æ‰€æœ‰å¯é…ç½®çš„å‚æ•°éƒ½åœ¨é‚£é‡Œå®šä¹‰å¥½äº†ã€‚**

#### Example

```bash
bash InfiR2_CPT_FP8_7B.sh --nodes N --rdzv_endpoint master_ip:master_port
```

## ğŸŒˆ ä½¿ç”¨ FP8 è¿›è¡Œç›‘ç£å¾®è°ƒ

æˆ‘ä»¬æä¾›äº†éµå¾ª [InfiAlign](https://arxiv.org/abs/2508.05496) è®ºæ–‡ï¼Œä½¿ç”¨ FP8 é‡åŒ–çš„ä¸¤é˜¶æ®µ SFT è®­ç»ƒè„šæœ¬ã€‚è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨ Ray è¿›è¡Œåˆ†å¸ƒå¼æ‰§è¡Œï¼Œå¹¶æ”¯æŒå¤šèŠ‚ç‚¹è®­ç»ƒé…ç½®ã€‚

- 7B SFT
  - é˜¶æ®µä¸€: [InfiR2_SFT_FP8_7B_stage1.sh](scripts/SFT/InfiR2_SFT_FP8_7B_stage1.sh).
  - é˜¶æ®µäºŒ: [InfiR2_SFT_FP8_7B_stage2.sh](scripts/SFT/InfiR2_SFT_FP8_7B_stage2.sh).
- 1.5B SFT
  - é˜¶æ®µä¸€: [InfiR2_SFT_FP8_1.5B_stage1.sh](scripts/SFT/InfiR2_SFT_FP8_1.5B_stage1.sh).
  - é˜¶æ®µäºŒ: [InfiR2_SFT_FP8_1.5B_stage2.sh](scripts/SFT/InfiR2_SFT_FP8_1.5B_stage2.sh).

#### é…ç½®

**æ•°æ®é›†:** ä¿®æ”¹ `DATA_DIR` å˜é‡ï¼Œä½¿å…¶æŒ‡å‘æ‚¨çš„è®­ç»ƒæ•°æ®ï¼š
```bash
DATA_DIR=/path/to/stage1_data
```

**æ¨¡å‹é…ç½®:** 
- HF_CHECKPOINT: æŒ‡å‘ HuggingFace æ ¼å¼çš„åŸºç¡€æ¨¡å‹è·¯å¾„ (ä¾‹å¦‚ Qwen2.5-7B)
- REF_LOAD: æŒ‡å‘ PyTorch åˆ†å¸ƒå¼æ ¼å¼çš„åŸºç¡€æ¨¡å‹æƒé‡è·¯å¾„

```bash
HF_CHECKPOINT=/path/to/base_models_hf/qwen2.5-7B/
REF_LOAD=/path/to/base_models_/qwen2.5-7B_torch_dist/
```
#### è¿è¡Œ
é¦–å…ˆï¼Œå¯åŠ¨ Ray é›†ç¾¤ï¼š
```bash
ray start --head --node-ip-address ${MASTER_ADDR} --num-gpus 8 --disable-usage-stats --dashboard-host=0.0.0.0 --dashboard-port=8265
```

ç„¶åï¼Œå¯åŠ¨è®­ç»ƒï¼š
```bash
bash scripts/SFT/InfiR2_SFT_FP8_stage1.sh
```

---

## ğŸ¯ ä½¿ç”¨ FP8 è¿›è¡Œå¼ºåŒ–å­¦ä¹ 

æˆ‘ä»¬çš„ RL è®­ç»ƒæµç¨‹åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆå‹ç¼©å“åº”é•¿åº¦ï¼Œç„¶åæ‰©å±•å®ƒã€‚åœ¨å¼€å§‹ RL è®­ç»ƒä¹‹å‰ï¼Œæ‚¨éœ€è¦å°† SFT æ£€æŸ¥ç‚¹è½¬æ¢ä¸º FP8 E8M0 æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ç”Ÿæˆ rollout é˜¶æ®µè¿›è¡Œé«˜æ•ˆçš„ FP8 æ¨ç†ã€‚

### ç”¨äº RL çš„æ¨¡å‹è½¬æ¢

å®Œæˆ SFT é˜¶æ®µäºŒåï¼Œè¯·å…ˆå°†æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ ¼å¼ï¼Œç„¶åå†è½¬æ¢ä¸º FP8 E8M0 æ ¼å¼ï¼š

```bash
# æ­¥éª¤ 1: å°† PyTorch åˆ†å¸ƒå¼æ£€æŸ¥ç‚¹è½¬æ¢ä¸º HuggingFace æ ¼å¼
PYTHONPATH=training/Megatron-LM:training/slime python tools/convert_torch_dist_to_hf.py \
    --input-dir /path/to/InfiR2_SFT_FP8_stg2 \
    --output-dir /path/to/InfiR2_SFT_FP8_stg2_hf \
    --origin-hf-dir /path/to/models/Qwen2.5-7B

# æ­¥éª¤ 2: å°† BF16 æ ¼å¼çš„ HuggingFace æ¨¡å‹è½¬æ¢ä¸º FP8 E8M0 æ ¼å¼
python tools/bf16_cast_fp8.py \
    --input-bf16-hf-path /path/to/InfiR2_SFT_FP8_stg2_hf \
    --output-fp8-hf-path /path/to/InfiR2_SFT_FP8_stg2_hf_e8m0 \
    --force-pow-2-scale True
```

è½¬æ¢åçš„ FP8 E8M0 æ¨¡å‹å°†ç”¨äº RL çš„ rollout é˜¶æ®µçš„æ¨ç†ï¼Œä»è€Œæ˜¾è‘—æå‡ç”Ÿæˆæ•ˆç‡ã€‚

- Stage 1: [InfiR2_RL_FP8_7B_stage1_4node.sh](scripts/RL/InfiR2_RL_FP8_7B_stage1_4node.sh) ï¼Œå“åº”é•¿åº¦ä¸º 8Kã€‚
- Stage 2: [InfiR2_RL_FP8_7B_stage2_4node.sh](scripts/RL/InfiR2_RL_FP8_7B_stage2_4node.sh)ï¼Œå“åº”é•¿åº¦ä¸º 8Kï¼Œå¹¶ä½¿ç”¨æ›´é«˜çš„æ¸©åº¦ç³»æ•°ã€‚

#### é…ç½®

**æ•°æ®é›†:** å°† `DATA_DIR` è®¾ç½®ä¸ºæ‚¨çš„ RL è®­ç»ƒæ•°æ®ï¼š
```bash
DATA_DIR=/path/to/data/dapo-math-17k.jsonl
```

**æ¨¡å‹é…:**
- `HF_CHECKPOINT`: æŒ‡å‘è½¬æ¢åçš„ FP8 E8M0 æ¨¡å‹è·¯å¾„ (ç”¨äºæ¨ç†)
- `REF_LOAD`: æŒ‡å‘ SFT é˜¶æ®µäºŒçš„ PyTorch åˆ†å¸ƒå¼æ ¼å¼æ£€æŸ¥ç‚¹è·¯å¾„

```bash
HF_CHECKPOINT=/path/to/InfiR2_SFT_FP8_stg2_hf_e8m0/
REF_LOAD=/path/to/InfiR2_SFT_FP8_stg2/
```

#### è¿è¡Œ 
å¯åŠ¨ RL è®­ç»ƒçš„æ–¹å¼ä¸ SFT ç›¸åŒã€‚é¦–å…ˆå¯åŠ¨ Rayï¼Œç„¶åè¿è¡Œè„šæœ¬ã€‚è¿™ç§åŸºäºè¯¾ç¨‹å­¦ä¹ çš„ç­–ç•¥å¯ä»¥ç¡®ä¿åœ¨ä¸åŒå“åº”é•¿åº¦è¦æ±‚ä¸‹çš„è®­ç»ƒç¨³å®šæ€§å’Œæœ€ä¼˜æ€§èƒ½ã€‚


## ğŸ“Š è¯„æµ‹

æˆ‘ä»¬ä½¿ç”¨ [evalscope](https://github.com/modelscope/evalscope) æ¡†æ¶è¿›è¡Œæ‰€æœ‰æ¨¡å‹è¯„æµ‹ï¼Œä»¥ç¡®ä¿å¯å¤ç°æ€§ã€‚æˆ‘ä»¬çš„è¯„æµ‹å¥—ä»¶åŒ…å«äº†å››ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ï¼Œå¹¶æä¾›äº†ç›¸åº”çš„è¯„æµ‹è„šæœ¬ã€‚

### ç¯å¢ƒè®¾ç½®

æˆ‘ä»¬å·²ç»éªŒè¯äº†æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨æœ€æ–°ç‰ˆæœ¬çš„ evalscope ä¸Šæ­£ç¡®è¿è¡Œï¼Œå¹¶å–å¾—ä¸€è‡´çš„æ€§èƒ½ç»“æœã€‚ç„¶è€Œï¼Œä¸ºäº†ä¸¥æ ¼å¤ç°æˆ‘ä»¬åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šçš„è¯„æµ‹ç»“æœï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ç‰¹å®šç‰ˆæœ¬çš„ evalscopeï¼š

**ç”¨äºå¤ç°çš„æ¨èç‰ˆæœ¬::**
- ä»“åº“: [evalscope](https://github.com/modelscope/evalscope)
- åˆ†æ”¯: `main`
- æ‹‰å–è¯·æ±‚: [Add qwen-code best practice doc #734](https://github.com/modelscope/evalscope/pull/734)

**å®‰è£…:**

è¯·éµå¾ªå®˜æ–¹æ–‡æ¡£è¿›è¡Œå®‰è£… [https://evalscope.readthedocs.io/zh-cn/latest/get_started/installation.html](https://evalscope.readthedocs.io/zh-cn/latest/get_started/installation.html)

```bash
git clone https://github.com/modelscope/evalscope.git
cd evalscope/
pip install -e .
```

### è¯„æµ‹åŸºå‡†

æˆ‘ä»¬ä¸ºå››ä¸ªå…³é”®çš„æ¨ç†åŸºå‡†æä¾›äº†è¯„æµ‹è„šæœ¬ï¼š

| åŸºå‡† | è„šæœ¬ | æœ€å¤§ Tokens | æ ·æœ¬æ•° | æ¸©åº¦ç³»æ•° |
|-----------|--------|------------|---------|-------------|
| AIME 2024 | [aime24_eval.sh](scripts/eval/aime24_eval.sh) | 31,000 | 32 | 0.65 |
| AIME 2025 | [aime25_eval.sh](scripts/eval/aime25_eval.sh) | 31,000 | 32 | 0.65 |
| GPQA | [gpqa_eval.sh](scripts/eval/gpqa_eval.sh) | 26,000 | 8 | 0.65 |
| LiveCodeBench | [livecodebenchv5_eval.sh](scripts/eval/livecodebenchv5_eval.sh) | 27,000 | 8 | 0.65 |

### è¿è¡Œè¯„æµ‹

æ¯ä¸ªè„šæœ¬éƒ½ä½¿ç”¨ slurm è¿›è¡Œä½œä¸šè°ƒåº¦ï¼Œå¹¶ä½¿ç”¨ SGLang æä¾›é«˜æ•ˆçš„æ¨ç†æœåŠ¡ã€‚è¯„æµ‹æµç¨‹åŒ…æ‹¬ï¼š

1. ä½¿ç”¨æ¨¡å‹å¯åŠ¨ä¸€ä¸ª SGLang æœåŠ¡
2. è¿è¡Œ evalscope å¹¶æŒ‡å®šç›¸åº”çš„åŸºå‡†æµ‹è¯•

## ğŸ™ è‡´è°¢

* æˆ‘ä»¬åœ¨æ­¤å¯¹ä»¥ä¸‹å¼€æºé¡¹ç›®è¡¨ç¤ºè¯šæŒšçš„æ„Ÿè°¢: [Slime](https://github.com/THUDM/slime), [Megatron](https://github.com/NVIDIA/Megatron-LM), [TransformerEngine](https://github.com/NVIDIA/TransformerEngine) and [Qwen2.5](https://github.com/QwenLM/Qwen2.5-Math)ã€‚

---

## ğŸ“Œ å¼•ç”¨


å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰ç”¨ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{wang2025infir2comprehensivefp8training,
      title={InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models}, 
      author={Wenjun Wang and Shuo Cai and Congkai Xie and Mingfa Feng and Yiming Zhang and Zhen Li and Kejing Yang and Ming Li and Jiannong Cao and Hongxia Yang},
      year={2025},
      eprint={2509.22536},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.22536}, 
}
```